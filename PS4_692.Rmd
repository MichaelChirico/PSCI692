---
title: "PS4 Through R"
author: "Michael Chirico"
date: "Compiled `r format(Sys.time(), '%B %d, %Y at %R')`"
output: 
  rmarkdown::html_document
---

## Problem 1

### Part b) simulation

```{r simul_corr}
library(data.table)
# CJ stands for cross-join; it returns all possible
#   pairs of elements of y1 and y2 as a data.table,
#   just like expand.grid does in base R but ~ 5x faster
pmf = CJ(y1 = 0:1, y2 = 0:2
         )[ , p := c(.38, .14, .24, .17, .02, .05)][]

# Jumping into the weeds here a bit.
# Approach: Sample **row numbers** of the pmf with
#  probability corresponding to the likelihood of the
#  corresponding cell in the pmf table.
#  Then draw the y1/y2 corresponding to that row number,
#  and calculate the correlation of y1/y2 that we draw

#  sample(.I, 1e6, prob = p, replace = TRUE)
#    * .I is the shorthand for the row number in a data.table
#    * 1e6 is the number of samples we want to draw
#    * prob = p tells sample not to draw the rows with equal
#      probability, but, e.g., row 1 will be chosen with
#      probability p[1]; row 2, with probability p[2], etc.
#  .SD[sample(...)]
#    * .SD, called within a [] call to a data.table, is simply
#      the data.table itself. So if we write pmf[ , .SD], it's
#      exactly equivalent to having written pmf[]. Oftentimes,
#      it's convenient to be able to refer to the data itself
#      within the [] call, as we do here. So .SD[sample(...)]
#      is the same as pmf[sample(...)], except that we use
#      variables within sample(...) that we can't use in the
#      first argument (called i) to [] -- namely, .I and p
#      Ultimately, .SD[sample(...)] extracts the rows (with
#      repetitions as necessary) corresponding to each element
#      of sample(...).
#  .SD[sample(...), cor(y1, y2)]
#    * Now that we've "subsetted" the data to those rows
#      corresponding to sample(...), we simply calculate the
#      correlation on our sample.
pmf[ , .SD[sample(.I, 1e6, prob = p, replace = TRUE), cor(y1, y2)]]
```

## Problem 2

### Part a)

Each element of the PMF matrix will be `c*(something)`; when we add up across all cells, it'll come to `c*(sum of cells)`, which we need to equal 1. Knowing this, we can solve:

```{r find_c}
x = c(1, 2, 4)
y = c(1, 3)
pmf.matrix = outer(x, y, function(x, y) x^2 + y^2)
pmf.matrix
cc = 1/sum(pmf.matrix)
cc
```

### Part b) - e), g)-i)

```{r probs_moments}
#Same approach as above, but done to death
pmf = CJ(x = x, y = y)[ , p := cc * c(pmf.matrix)]

pmf[ , .SD[sample(.I, 1e6, prob = p, replace = TRUE),
           #Using backticks since these aren't kosher variable names
           .(`(b)` = mean(y < x), `(c)` = mean(y > x), 
             `(d)` = mean(y == x), `(e)` = mean(y == 3),
             `(g.1)` = mean(x), `(g.2)` = mean(y),
             `(g.3)` = mean(x*y), `(h.1)` = var(x),
             `(h.2)` = var(y), `(h.3)` = var(x + y),
             `(i.1)` = mean(x[x >= y]),
             `(i.2)` = var(x[x >= y]))]]
```

## Problem 3

### Part c)

Doing the simulation for an unknown joint CDF is a bit tough. So we're instead going to approximate by discretizing.

```{r cdf_discr}
pdf = CJ(y1 = seq(0, 1, length.out = 1000L),
         y2 = seq(0, 1, length.out = 1000L)
         #have to normalize by the number of points
         )[ , p := 4 * y1 * y2 / .N]

#sanity check
pdf[ , sum(p)]

#now calculate CDF
pdf[y1 <= .5 & y2 <= .75, sum(p)]
```

### Part d), e)

```{r marginals}
#marginal dist'n for Y1
pdf[ , .(p_1 = sum(p)), by = y1]

#marginal dist'n for Y2
pdf[ , .(p_2 = sum(p)), by = y2]
```

### Part g)

```{r var}
pdf[ , .SD[sample(.I, 1e6, prob = p, replace = TRUE), var(y1 - y2)]]
```
